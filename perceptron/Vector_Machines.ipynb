{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernals and the Kernal Trick\n",
    "\n",
    "The perceptron separtes instances of the positive class from\n",
    "instances of the negative class by using a decision boundry and\n",
    "makes predictions using a prediction boundry.\n",
    "\n",
    "\n",
    "* Prediction Boundry: $h(x) = sign(f(x))$\n",
    "* Decision Boundry:\n",
    "  * Primal Form:\n",
    "    * Computes the inner product of the model parameters\n",
    "    * Computes the test instance's feature vector\n",
    "    * $f(x) = \\langle x,y \\rangle + b$\n",
    "  * Dual Form:\n",
    "    * Computes the inner product of the training test instance's feature vector\n",
    "    * $f(x) = \\sum \\alpha_i y_i \\langle x_i, x \\rangle + b$\n",
    "    * Map to higher dimentional space\n",
    "      * $f(x) = \\sum \\alpha_i y_i \\langle (\\phi x_i), (\\phi x) \\rangle + b$\n",
    "      * Warning: introduces computation and generalisation problems and\n",
    "      requires a large amount of processing power\n",
    "\n",
    "### Solution: Kernel\n",
    "A kernel is a function that, when given the original feature vectors,\n",
    "returns the same value as the dot product of its corresponding\n",
    "mapped feature vectors.\n",
    "\n",
    "* Kernels\n",
    "  * Do not explicitly map feature vectors to a higher dimentional space\n",
    "  * Do not calculate the dot product of the mapped vectors\n",
    "    * Produce the same value through a different set of operations that\n",
    "    can often be computed more effciently\n",
    "  * $K(x, z) = \\langle \\phi(x), \\phi(z) \\rangle$\n",
    "  \n",
    "How kernels work. Imagine we wish to mapped the following feature\n",
    "vectors to a higher dimentional space.\n",
    "\n",
    "*Feature Vectors:*  \n",
    "$x = (x_1, x_2)$  \n",
    "$z = (z_1, z_2)$\n",
    "\n",
    "*Transformation:*\n",
    "$\\phi(x) = x^2$\n",
    "\n",
    "*Dot Product:*  \n",
    "$\\langle \\phi(x), \\phi(z) \\rangle = \\langle(x_1^2 , x_2^2, \\sqrt{2} x_1 x_2), \n",
    "(z_1^2 , z_2^2, \\sqrt{2} z_1 z_2)\\rangle$\n",
    "\n",
    "*Kernel Verification:*  \n",
    "$K(x,z) = \\langle x,z \\rangle^2 = (x_1z_1 + x_2z_2)^2 = x_1^2z_1^2 + 2x_1z_1x_2z_2 + x_2^2z_2^2$  \n",
    "$K(x,z) = \\langle\\phi(x),\\phi(z)\\rangle$\n",
    "\n",
    "Plugging in values, you can see that the Kernel K(x,z) produces the same\n",
    "value as the dot product of the mapped features but without acutally \n",
    "mapping them; this less calculations are required.\n",
    "\n",
    "* Some Kernel function in Scikit-learn\n",
    "  * Polynomial: $K(x,x') = (\\lambda\\langle x-x'\\rangle + r)^k$\n",
    "    * Quadratic where k is equal to 2\n",
    "      * Commonly used in natural language processing\n",
    "  * Sigmoid: $K(x,x') = \\tanh{(\\lambda\\langle x-x'\\rangle + r)}$\n",
    "  * Guassian: $K(x,x') = exp(-\\lambda\\ |x-x'|^2)$\n",
    "    * Good choice for problems requiring non-linear models\n",
    "    * Gaussian kernel is a radial bias function\n",
    "    * Hyperplane in the mapped feature space = Hypersphere in original space\n",
    "    * Feature space produced can have an infinite number of dimentions\n",
    "    * Scaling is especially important\n",
    "  * Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Margin Classification\n",
    "Using a decision boundry, an instance can be more confidently identified as\n",
    "in the positive or negative class the further away from the decision boundry\n",
    "it lies. The confidence of the prediction can be estimated using the \n",
    "**functional margin**. Large functional margins are more confident while\n",
    "lower ones are less confident. A negative functional margin would indicate\n",
    "a misclassification.\n",
    "\n",
    "* Functional Margin:\n",
    "  * Instances for which functional margin is 1 are called support vectors\n",
    "    * These instances are suffient for defining the decision boundry\n",
    "    * Other instances are not required to predict the class of a test instance\n",
    "* Geometric Margin:\n",
    "  * Maximum width of the band that separates support vectors\n",
    "  * Geometric margin = Normalised functional margin\n",
    "    * Scaling is necessary as the functional margin can be scaled by w, causing\n",
    "    problems for training\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD2CAYAAADGbHw0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5180f0400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classifying images of handwritten numbers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Fetch the data\n",
    "mnist = fetch_mldata('MNIST original', data_home='data/mnist')\n",
    "\n",
    "# Create subplots of 5 images of the digits 0, 1, & 2\n",
    "counter = 1\n",
    "for i in range(1, 4):\n",
    "    for j in range(1, 6):\n",
    "        plt.subplot(3, 5, counter)\n",
    "        plt.imshow(mnist.data[(i - 1) * 8000 + j].reshape((28, 28)), cmap=cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "        counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# The script will fork additional processes during GridSearch,\n",
    "# which requires execution from a main block\n",
    "if __name__ == '__main__':\n",
    "    # Scale features and center about the origin\n",
    "    X, y = mnist.data, mnist.target\n",
    "    X = X/255.0*2 - 1\n",
    "    # Split pre-processed data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)\n",
    "    \n",
    "    # Establish a pipeline using SVC (support vector classifier)\n",
    "    # Kernal is set to use radial basis fuction\n",
    "    # 'C' controls regularisation\n",
    "    # NOTE: the keywork argument 'degree' should also be set when polynomial kernel is used\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', SVC(kernel='rbf', gamma=0.01, C=100))\n",
    "    ])\n",
    "    \n",
    "    parameters = {\n",
    "        'clf__gamma': (0.01, 0.03, 0.1, 0.3, 1),\n",
    "        'clf__C': (0.1, 0.3, 1, 3, 10, 30),\n",
    "    }\n",
    "    \n",
    "    # Tune parameters using gridsearch. This will take a while\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=2, verbose=1, scoring='accuracy')\n",
    "    \n",
    "    # Train the model and print the best scores\n",
    "    grid_search.fit(X_train[:10000], y_train[:10000])\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifying characters in natural images\n",
    "# The dataset can be found at: http://ee.surrey.ac.uk/CVSSP/chars74k/\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "\n",
    "# Convert images to greyscale using 'pillow' and resize before\n",
    "# adding them to a numpy array\n",
    "X = []\n",
    "y = []\n",
    "for path, subdirs, files in os.walk('data/English/Img/GoodImg/Bmp/'):\n",
    "    for filename in files:\n",
    "        f = os.path.join(path, filename)\n",
    "        target = filename[3:filename.index('-')]\n",
    "        img = Image.open(f).convert('L').resize((30, 30), resample=Image.LANCZOS)\n",
    "        X.append(np.array(img).reshape(900,))\n",
    "        y.append(target)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=11)\n",
    "\n",
    "# Create SVC instance and parameters\n",
    "pipeline = Pipeline([\n",
    "    ('clf', SVC(kernel='rbf', gamma=0.01, C=100))\n",
    "])\n",
    "parameters = {\n",
    "    'clf__gamma': (0.01, 0.03, 0.1, 0.3, 1),\n",
    "    'clf__C': (0.1, 0.3, 1, 3, 10, 30),\n",
    "}\n",
    "\n",
    "# Fork the main block and run the model\n",
    "if __name__ == '__main__':\n",
    "    # GridSearch to tune the parameters and evaluate the model on the test data\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
