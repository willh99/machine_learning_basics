{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Categorical Variables can take one of a fixed set of values.\n",
    "# They often use one-hot encoding in which the eplainitory variable\n",
    "# is represented using a binary feature representing one of its\n",
    "# possible values.\n",
    "# Example: Represent cities with one-hot encoding\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "onehot_encoder = DictVectorizer()\n",
    "\n",
    "X = [\n",
    "    {'city': 'New York'},\n",
    "    {'city': 'San Francisco'},\n",
    "    {'city': 'Chapel Hill'}\n",
    "]\n",
    "print(onehot_encoder.fit_transform(X).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.70710678 -1.38873015  0.52489066  0.59299945 -1.35873244]\n",
      " [ 0.         -0.70710678  0.46291005  0.87481777  0.81537425  1.01904933]\n",
      " [ 0.          1.41421356  0.9258201  -1.39970842 -1.4083737   0.33968311]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization is needed so that one feature's variance does not cause it to\n",
    "# dominate over the learning algorithm.\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [0., 0., 5., 13., 9., 1.],\n",
    "    [0., 0., 13., 15., 10., 15.],\n",
    "    [0., 3., 15., 2., 0., 11.]\n",
    "])\n",
    "print(preprocessing.scale(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# StandardScaler works by subtracting the mean of a feature from each instance's value\n",
    "# and then dividing by the feature's standard deviation\n",
    "\n",
    "# RobustScaler is an alternative which subtracts the median and divides by\n",
    "# the interquartile range. Quartiles are calulated by splitting sorted datasets\n",
    "# into four parts of equal size. Second quartile is the median while the\n",
    "# Interquartile range is the difference of the third and first quartiles.\n",
    "# This mitigates the effect of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting features from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
